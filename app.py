import hashlib
import streamlit as st
import io
import os
import re
import gspread
import openpyxl
from openpyxl.utils.cell import column_index_from_string
import json
import cv2
import numpy as np
import pandas as pd
import random
import time as pytime
import math
from google.oauth2 import service_account
from google.cloud import vision
from google.cloud import storage
from datetime import datetime, timedelta, timezone, time # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° time
import string

# =========================================================
# --- üì¶ CONFIGURATION ---
# =========================================================
BUCKET_NAME = 'water-meter-images-watertreatmentplant'
FIXED_FOLDER_ID = '1XH4gKYb73titQLrgp4FYfLT2jzYRgUpO' 

# =========================================================
# --- üïí TIMEZONE HELPER ---
# =========================================================
def get_thai_time():
    """‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡πÇ‡∏ã‡∏ô‡πÑ‡∏ó‡∏¢ (UTC+7)"""
    tz = timezone(timedelta(hours=7))
    return datetime.now(tz)

# =========================================================
# --- PAGE CONFIG ---
# =========================================================
st.set_page_config(page_title="Smart Meter System", page_icon="üíß", layout="centered")

st.markdown("""
    <style>
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .status-box { padding: 15px; border-radius: 10px; margin-bottom: 15px; border: 1px solid #ddd; }
    .status-warning { background-color: #fff3cd; color: #856404; }
    .report-badge {
        background-color: #e3f2fd; color: #0d47a1;
        padding: 4px 8px; border-radius: 4px; font-size: 0.8em; font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# =========================================================
# --- CONFIGURATION & SECRETS ---
# =========================================================
if 'gcp_service_account' in st.secrets:
    try:
        key_dict = json.loads(st.secrets['gcp_service_account'])
        if 'private_key' in key_dict:
            key_dict['private_key'] = key_dict['private_key'].replace('\\n', '\n')

        creds = service_account.Credentials.from_service_account_info(
            key_dict,
            scopes=[
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
                "https://www.googleapis.com/auth/cloud-platform"
            ]
        )
    except Exception as e:
        st.error(f"‚ùå Error loading secrets: {e}")
        st.stop()
else:
    st.error("‚ùå Secrets not found.")
    st.stop()

gc = gspread.authorize(creds)
DB_SHEET_NAME = 'WaterMeter_System_DB'
REAL_REPORT_SHEET = 'TEST waterreport'
VISION_CLIENT = vision.ImageAnnotatorClient(credentials=creds)
STORAGE_CLIENT = storage.Client(credentials=creds)

# =========================================================
# --- CLOUD STORAGE HELPERS ---
# =========================================================
def upload_image_to_storage(image_bytes, file_name):
    try:
        bucket = STORAGE_CLIENT.bucket(BUCKET_NAME)
        blob = bucket.blob(file_name)

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Content-Type ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå (‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏π‡∏õ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
        ext = str(file_name).lower().split(".")[-1] if "." in str(file_name) else "jpg"
        content_type = "image/png" if ext == "png" else "image/jpeg"

        blob.upload_from_string(image_bytes, content_type=content_type)
        return blob.public_url
    except Exception as e:
        return f"Error: {e}"


# =========================================================
# --- üñºÔ∏è REFERENCE IMAGE (Auto Find) ---
# =========================================================
REF_IMAGE_FOLDER = "ref_images"

@st.cache_data(ttl=3600)
def load_ref_image_bytes_any(point_id: str):
    """
    ‡∏´‡∏≤ reference ‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á:
    1) ref_images/POINT.(jpg/png)
    2) POINT.(jpg/png) ‡πÉ‡∏ô root
    3) ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‚Üí ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ POINT_ (‡πÄ‡∏ä‡πà‡∏ô POINT_2026...jpg)
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (bytes, path) ‡∏´‡∏£‡∏∑‡∏≠ (None, None)
    """
    pid = str(point_id).strip().upper()
    bucket = STORAGE_CLIENT.bucket(BUCKET_NAME)

    # 1) ‡∏•‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô
    candidates = []
    for ext in ["jpg", "jpeg", "png", "JPG", "JPEG", "PNG"]:
        candidates += [
            f"{REF_IMAGE_FOLDER}/{pid}.{ext}",
            f"{pid}.{ext}",
        ]

    # ‡∏•‡∏≠‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏£‡∏á ‡πÜ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ exists ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô)
    for path in candidates:
        try:
            blob = bucket.blob(path)
            data = blob.download_as_bytes()
            if data:
                return data, path
        except Exception:
            pass

    # 2) ‡∏´‡∏≤‡πÅ‡∏ö‡∏ö prefix ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (POINT_....jpg/png)
    try:
        blobs = list(bucket.list_blobs(prefix=f"{pid}_"))
        blobs = [b for b in blobs if str(b.name).lower().endswith((".jpg", ".jpeg", ".png"))]
        if blobs:
            blobs.sort(key=lambda b: b.updated or datetime.min, reverse=True)
            b = blobs[0]
            data = b.download_as_bytes()
            return data, b.name
    except Exception:
        pass

    return None, None


# =========================================================
# --- SHEET HELPERS ---
# =========================================================
def col_to_index(col_str):
    col_str = str(col_str).upper().strip()
    num = 0
    for c in col_str:
        if c in string.ascii_letters:
            num = num * 26 + (ord(c.upper()) - ord('A')) + 1
    return num

# ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Sheet ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏•‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
def get_thai_sheet_name(sh, target_date):
    thai_months = ["‡∏°.‡∏Ñ.", "‡∏Å.‡∏û.", "‡∏°‡∏µ.‡∏Ñ.", "‡πÄ‡∏°.‡∏¢.", "‡∏û.‡∏Ñ.", "‡∏°‡∏¥.‡∏¢.", "‡∏Å.‡∏Ñ.", "‡∏™.‡∏Ñ.", "‡∏Å.‡∏¢.", "‡∏ï.‡∏Ñ.", "‡∏û.‡∏¢.", "‡∏ò.‡∏Ñ."]
    
    # ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (target_date) ‡πÅ‡∏ó‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    m_idx = target_date.month - 1
    # ‡∏õ‡∏µ‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏±‡∏Å‡∏£‡∏≤‡∏ä
    yy = str(target_date.year + 543)[-2:]
    
    patterns = [f"{thai_months[m_idx]}{yy}", f"{thai_months[m_idx][:-1]}{yy}", f"{thai_months[m_idx]} {yy}", f"{thai_months[m_idx][:-1]} {yy}"]
    all_sheets = [s.title for s in sh.worksheets()]
    for p in patterns:
        if p in all_sheets:
            return p
    return None

def find_day_row_exact(ws, day: int):
    col = ws.col_values(1)
    for i, v in enumerate(col, start=1):
        try:
            if int(str(v).strip()) == int(day):
                return i
        except:
            pass
    return None

@st.cache_data(ttl=300)
def load_points_master():
    sh = gc.open(DB_SHEET_NAME)
    ws = sh.worksheet("PointsMaster")
    return ws.get_all_records()

def safe_int(x, default=0):
    try: return int(float(x)) if x and str(x).strip() else default
    except: return default

def safe_float(x, default=0.0):
    try: return float(x) if x and str(x).strip() else default
    except: return default

def parse_bool(v):
    if v is None: return False
    return str(v).strip().lower() in ("true", "1", "yes", "y", "t", "on")

def get_meter_config(point_id):
    try:
        records = load_points_master()
        pid = str(point_id).strip().upper()
        for item in records:
            if str(item.get('point_id', '')).strip().upper() == pid:
                item['decimals'] = safe_int(item.get('decimals'), 0)
                item['keyword'] = str(item.get('keyword', '')).strip()
                exp = safe_int(item.get('expected_digits'), 0)
                if exp == 0: exp = safe_int(item.get('int_digits'), 0)
                item['expected_digits'] = exp
                item['report_col'] = str(item.get('report_col', '')).strip()
                item['ignore_red'] = parse_bool(item.get('ignore_red'))
                item['roi_x1'] = safe_float(item.get('roi_x1'), 0.0)
                item['roi_y1'] = safe_float(item.get('roi_y1'), 0.0)
                item['roi_x2'] = safe_float(item.get('roi_x2'), 0.0)
                item['roi_y2'] = safe_float(item.get('roi_y2'), 0.0)
                item['type'] = str(item.get('type', '')).strip()
                item['name'] = str(item.get('name', '')).strip()
                return item
        return None
    except: return None

# ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏£‡∏±‡∏ö target_date ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏á‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ß‡∏±‡∏ô
def export_to_real_report(point_id, read_value, inspector, report_col, target_date, debug=False):
    """‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏•‡∏á Google Sheet REAL_REPORT_SHEET
    - debug=False: ‡∏Ñ‡∏∑‡∏ô True/False ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    - debug=True : ‡∏Ñ‡∏∑‡∏ô (ok, message) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡πà‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤
    """

    def _ret(ok, msg=""):
        return (ok, msg) if debug else ok

    if not report_col:
        return _ret(False, "report_col ‡∏ß‡πà‡∏≤‡∏á")
    report_col = str(report_col).strip()
    if report_col in ("-", "‚Äî", "‚Äì"):
        return _ret(False, "report_col ‡πÄ‡∏õ‡πá‡∏ô '-' (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô PointsMaster)")

    # ‡πÄ‡∏õ‡∏¥‡∏î‡∏ä‡∏µ‡∏ó
    try:
        sh = gc.open(REAL_REPORT_SHEET)
    except Exception as e:
        return _ret(False, f"‡πÄ‡∏õ‡∏¥‡∏î‡∏ä‡∏µ‡∏ó '{REAL_REPORT_SHEET}' ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")

    # ‡∏´‡∏≤‡πÅ‡∏ó‡πá‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    sheet_name = None
    try:
        sheet_name = get_thai_sheet_name(sh, target_date)
    except Exception:
        sheet_name = None

    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‚Üí ‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ü‡∏±‡∏ã‡∏ã‡∏µ‡πà (‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡∏à‡∏∏‡∏î)
    if not sheet_name:
        try:
            thai_months = ["‡∏°.‡∏Ñ.", "‡∏Å.‡∏û.", "‡∏°‡∏µ.‡∏Ñ.", "‡πÄ‡∏°.‡∏¢.", "‡∏û.‡∏Ñ.", "‡∏°‡∏¥.‡∏¢.", "‡∏Å.‡∏Ñ.", "‡∏™.‡∏Ñ.", "‡∏Å.‡∏¢.", "‡∏ï.‡∏Ñ.", "‡∏û.‡∏¢.", "‡∏ò.‡∏Ñ."]
            m_idx = target_date.month - 1
            yy2 = str(target_date.year + 543)[-2:]
            yy4 = str(target_date.year + 543)
            m_norm = thai_months[m_idx].replace(".", "").replace(" ", "")

            def norm(x):
                return str(x).replace(".", "").replace(" ", "").strip()

            for t in [s.title for s in sh.worksheets()]:
                tn = norm(t)
                if (m_norm in tn) and (yy2 in tn or yy4 in tn):
                    sheet_name = t
                    break
        except Exception:
            sheet_name = None

    # ‡πÄ‡∏õ‡∏¥‡∏î worksheet
    try:
        ws = sh.worksheet(sheet_name) if sheet_name else sh.get_worksheet(0)
    except Exception as e:
        return _ret(False, f"‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏ö '{sheet_name}' ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")

    # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô
    try:
        target_day = int(target_date.day)
        target_row = find_day_row_exact(ws, target_day) or (6 + target_day)
    except Exception as e:
        return _ret(False, f"‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

    # ‡∏´‡∏≤ col
    target_col = col_to_index(report_col)
    if target_col == 0:
        return _ret(False, f"report_col '{report_col}' ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")

    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤
    try:
        ws.update_cell(target_row, target_col, read_value)
        return _ret(True, f"OK ‚Üí sheet='{ws.title}', row={target_row}, col={report_col}({target_col}), val={read_value}")
    except Exception as e:
        return _ret(False, f"‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")



# ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏£‡∏±‡∏ö target_date ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏á Timestamp ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ß‡∏±‡∏ô

# =========================================================
# --- üöÄ QUOTA-SAFE BATCH HELPERS (Sheets) ---
# =========================================================
def _is_quota_429(err: Exception) -> bool:
    msg = str(err)
    return ("429" in msg) or ("Quota exceeded" in msg) or ("Read requests" in msg)

def _with_retry(fn, *args, max_retries: int = 6, base_sleep: float = 0.8, **kwargs):
    """
    Retry wrapper for Google Sheets calls that may hit 429 quota.
    - Exponential backoff + jitter
    """
    last_err = None
    for i in range(max_retries):
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            last_err = e
            if _is_quota_429(e) and i < max_retries - 1:
                # backoff: 0.8, 1.6, 3.2, ...
                sleep_s = base_sleep * (2 ** i) + random.random() * 0.4
                pytime.sleep(sleep_s)
                continue
            raise
    if last_err:
        raise last_err

def export_many_to_real_report_batch(items: list, target_date, debug: bool = False):
    """
    Export ‡∏´‡∏•‡∏≤‡∏¢‡∏à‡∏∏‡∏î‡∏•‡∏á WaterReport ‡∏î‡πâ‡∏ß‡∏¢ 1 batch_update (‡∏•‡∏î Read/Write requests ‡∏°‡∏≤‡∏Å ‡πÜ)
    items: list[dict] ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ keys: point_id, value, report_col
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤:
      - ok_pids: list[str]
      - fail_list: list[tuple(pid, reason)]
    """
    ok_pids = []
    fail_list = []

    if not items:
        return ok_pids, fail_list

    # ‡πÄ‡∏õ‡∏¥‡∏î‡∏ä‡∏µ‡∏ó‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + retry ‡∏Å‡∏±‡∏ô quota
    try:
        sh = _with_retry(gc.open, REAL_REPORT_SHEET)
    except Exception as e:
        reason = f"‡πÄ‡∏õ‡∏¥‡∏î‡∏ä‡∏µ‡∏ó '{REAL_REPORT_SHEET}' ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}"
        for it in items:
            fail_list.append((it.get("point_id", ""), reason))
        return ok_pids, fail_list

    # ‡∏´‡∏≤‡πÅ‡∏ó‡πá‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    sheet_name = None
    try:
        sheet_name = get_thai_sheet_name(sh, target_date)
    except Exception:
        sheet_name = None

    # fallback ‡πÅ‡∏ö‡∏ö‡∏ü‡∏±‡∏ã‡∏ã‡∏µ‡πà (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
    if not sheet_name:
        try:
            thai_months = ["‡∏°.‡∏Ñ.", "‡∏Å.‡∏û.", "‡∏°‡∏µ.‡∏Ñ.", "‡πÄ‡∏°.‡∏¢.", "‡∏û.‡∏Ñ.", "‡∏°‡∏¥.‡∏¢.", "‡∏Å.‡∏Ñ.", "‡∏™.‡∏Ñ.", "‡∏Å.‡∏¢.", "‡∏ï.‡∏Ñ.", "‡∏û.‡∏¢.", "‡∏ò.‡∏Ñ."]
            m_idx = target_date.month - 1
            yy2 = str(target_date.year + 543)[-2:]
            yy4 = str(target_date.year + 543)
            m_norm = thai_months[m_idx].replace(".", "").replace(" ", "")

            def norm(x):
                return str(x).replace(".", "").replace(" ", "").strip()

            for t in [s.title for s in sh.worksheets()]:
                tn = norm(t)
                if (m_norm in tn) and (yy2 in tn or yy4 in tn):
                    sheet_name = t
                    break
        except Exception:
            sheet_name = None

    # ‡πÄ‡∏õ‡∏¥‡∏î worksheet ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + retry
    try:
        ws = _with_retry(sh.worksheet, sheet_name) if sheet_name else _with_retry(sh.get_worksheet, 0)
    except Exception as e:
        reason = f"‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏ö '{sheet_name}' ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}"
        for it in items:
            fail_list.append((it.get("point_id", ""), reason))
        return ok_pids, fail_list

    # ‚úÖ ‡∏•‡∏î Read requests: ‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£ row ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡∏ñ‡πâ‡∏≤ template ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏¥‡∏î find_day_row_exact ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ)
    try:
        target_row = 6 + int(target_date.day)
    except Exception:
        target_row = 6 + 1

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° batch ranges
    data = []
    for it in items:
        pid = str(it.get("point_id", "")).strip().upper()
        report_col = str(it.get("report_col", "")).strip()
        val = it.get("value", "")

        if not report_col or report_col in ("-", "‚Äî", "‚Äì"):
            fail_list.append((pid, "report_col ‡∏ß‡πà‡∏≤‡∏á/‡πÄ‡∏õ‡πá‡∏ô '-' ‡πÉ‡∏ô PointsMaster"))
            continue

        target_col = col_to_index(report_col)
        if target_col <= 0:
            fail_list.append((pid, f"report_col '{report_col}' ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"))
            continue

        # A1 ‡πÄ‡∏ä‡πà‡∏ô "Y18"
        a1 = gspread.utils.rowcol_to_a1(target_row, target_col)
        data.append({"range": a1, "values": [[val]]})
        ok_pids.append(pid)

    if not data:
        return [], fail_list

    # batch_update ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + retry ‡∏Å‡∏±‡∏ô quota
    try:
        _with_retry(ws.batch_update, data, value_input_option="USER_ENTERED")
        return ok_pids, fail_list
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤ batch fail ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î fail (‡πÉ‡∏´‡πâ user ‡∏Å‡∏î‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ)
        reason = f"‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (batch_update): {e}"
        for pid in ok_pids:
            fail_list.append((pid, reason))
        return [], fail_list

def append_rows_dailyreadings_batch(rows: list):
    """
    append_rows ‡∏•‡∏á DailyReadings ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏•‡∏î requests)
    rows: list[list] ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö schema DailyReadings
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ (ok:bool, message:str)
    """
    if not rows:
        return True, "NO_ROWS"

    try:
        sh = _with_retry(gc.open, DB_SHEET_NAME)
        ws = _with_retry(sh.worksheet, "DailyReadings")
        _with_retry(ws.append_rows, rows, value_input_option="USER_ENTERED")
        return True, f"APPENDED {len(rows)}"
    except Exception as e:
        return False, str(e)

def save_to_db(point_id, inspector, meter_type, manual_val, ai_val, status, target_date, image_url="-"):
    try:
        sh = gc.open(DB_SHEET_NAME)
        ws = sh.worksheet("DailyReadings")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Timestamp: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å + ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Ñ‡∏µ‡∏¢‡πå‡∏ï‡∏≠‡∏ô‡∏Å‡∏µ‡πà‡πÇ‡∏°‡∏á ‡πÅ‡∏ï‡πà‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)
        current_time = get_thai_time().time()
        record_timestamp = datetime.combine(target_date, current_time)
        
        row = [record_timestamp.strftime("%Y-%m-%d %H:%M:%S"), meter_type, point_id, inspector, manual_val, ai_val, status, image_url]
        ws.append_row(row)
        return True
    except: return False

# =========================================================
# --- üß† OCR ENGINE (Clean & Robust) ---
# =========================================================

# ------------------------ SCADA Excel Upload (Export) ------------------------
def _normalize_scada_time(value):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö 'HH:MM' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢ (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö time/datetime/str/float)
    """
    import datetime as _dt
    if value is None:
        return None

    # Excel time (‡πÄ‡∏ä‡πà‡∏ô 0.9965) = ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô
    if isinstance(value, (int, float)) and 0 <= float(value) < 1:
        seconds = int(round(float(value) * 24 * 60 * 60))
        h = (seconds // 3600) % 24
        m = (seconds % 3600) // 60
        return f"{h:02d}:{m:02d}"

    if isinstance(value, _dt.datetime):
        value = value.time()
    if isinstance(value, _dt.time):
        return f"{value.hour:02d}:{value.minute:02d}"

    s = str(value).strip()
    # 23.55
    if re.match(r"^\d{1,2}\.\d{2}$", s):
        h, m = s.split(".")
        return f"{int(h):02d}:{int(m):02d}"
    # 23:55 or 23:55:00
    if re.match(r"^\d{1,2}:\d{2}", s):
        parts = s.split(":")
        return f"{int(parts[0]):02d}:{int(parts[1]):02d}"

    return None


def _strip_date_prefix(name: str) -> str:
    """
    ‡πÄ‡∏≠‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 2026_01_12_Daily_Report -> Daily_Report)
    """
    base = os.path.splitext(os.path.basename(name))[0]
    base = re.sub(r"^\d{4}_\d{2}_\d{2}_", "", base)
    return base.strip().lower()


def load_scada_excel_mapping(local_path: str = "DB_Water_Scada.xlsx", uploaded_bytes=None):
    """
    ‡∏≠‡πà‡∏≤‡∏ô mapping ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå DB_Water_Scada.xlsx
    ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á: PointID, File, Sheet, Time, Colume
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á dict: {point_id, file_key, sheet, time, col}
    """
    if uploaded_bytes:
        wb = openpyxl.load_workbook(io.BytesIO(uploaded_bytes), data_only=True)
    else:
        if not os.path.exists(local_path):
            return []
        wb = openpyxl.load_workbook(local_path, data_only=True)

    ws = wb[wb.sheetnames[0]]

    # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    header_row = None
    header_map = {}
    for r in range(1, min(ws.max_row, 30) + 1):
        row_vals = [ws.cell(r, c).value for c in range(1, min(ws.max_column, 20) + 1)]
        row_str = [str(v).strip().lower() if v is not None else "" for v in row_vals]
        if "pointid" in row_str and "file" in row_str and "sheet" in row_str:
            header_row = r
            for idx, name in enumerate(row_str, start=1):
                if name in ["pointid", "file", "sheet", "time", "colume", "column"]:
                    header_map[name] = idx
            break

    if not header_row:
        return []

    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏™‡∏∞‡∏Å‡∏î Colume/Column
    col_idx = header_map.get("colume") or header_map.get("column")
    out = []
    for r in range(header_row + 1, ws.max_row + 1):
        point_id = ws.cell(r, header_map["pointid"]).value
        if point_id is None or str(point_id).strip() == "":
            continue

        file_key = ws.cell(r, header_map["file"]).value
        sheet = ws.cell(r, header_map["sheet"]).value
        t = ws.cell(r, header_map.get("time", 0)).value if header_map.get("time") else None
        col = ws.cell(r, col_idx).value if col_idx else None

        out.append({
            "point_id": str(point_id).strip(),
            "file_key": str(file_key).strip() if file_key is not None else "",
            "sheet": str(sheet).strip() if sheet is not None else "Sheet1",
            "time": t,
            "col": str(col).strip() if col is not None else "",
        })
    return out


def _find_cell_exact(ws, target_text: str, max_rows=60, max_cols=40):
    target = target_text.strip().lower()
    for r in range(1, min(ws.max_row, max_rows) + 1):
        for c in range(1, min(ws.max_column, max_cols) + 1):
            v = ws.cell(r, c).value
            if isinstance(v, str) and v.strip().lower() == target:
                return r, c
    return None


def _hhmm_to_minutes(hhmm: str):
    try:
        h, m = str(hhmm).split(":")
        return int(h) * 60 + int(m)
    except Exception:
        return None


def _extract_value_from_ws(ws, target_time_hhmm, value_col_letter: str, time_header="Time"):
    """
    ‡∏´‡∏≤ row ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡πÄ‡∏ä‡πà‡∏ô 'Y')
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πä‡∏∞: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏•‡∏≤ "‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
    - ‡∏ñ‡πâ‡∏≤ cell ‡∏ß‡πà‡∏≤‡∏á: ‡πÑ‡∏•‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (value, status)
    """
    hdr = _find_cell_exact(ws, time_header)
    if not hdr:
        return None, "NO_TIME_HEADER"

    hdr_row, time_col = hdr

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏≤‡∏ó‡∏µ
    time_rows = []
    for r in range(hdr_row + 1, ws.max_row + 1):
        v = ws.cell(r, time_col).value
        hhmm = _normalize_scada_time(v)
        mm = _hhmm_to_minutes(hhmm) if hhmm else None
        if mm is not None:
            time_rows.append((r, mm))

    if not time_rows:
        return None, "NO_DATA_ROW"

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ñ‡∏ß‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
    if target_time_hhmm:
        tmm = _hhmm_to_minutes(target_time_hhmm)
        if tmm is None:
            target_row = time_rows[-1][0]
        else:
            target_row = min(time_rows, key=lambda x: abs(x[1] - tmm))[0]
    else:
        target_row = time_rows[-1][0]

    # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡πà‡∏≤
    try:
        col_idx = column_index_from_string(str(value_col_letter).strip().upper())
    except Exception:
        return None, "BAD_COLUMN"

    # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏á ‚Üí ‡πÑ‡∏•‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
    for rr in range(target_row, hdr_row, -1):
        val = ws.cell(rr, col_idx).value
        if val not in (None, "", " "):
            return val, "OK"

    return None, "EMPTY_CELL"

def extract_scada_values_from_exports(mapping_rows, uploaded_exports: dict):
    """
    mapping_rows: list[dict] ‡∏à‡∏≤‡∏Å load_scada_excel_mapping
    uploaded_exports: dict filename->bytes ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤:
      - results: list[dict] ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
      - missing: list[dict] ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
    """
    # ‡πÇ‡∏´‡∏•‡∏î workbook ‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå (cache ‡πÉ‡∏ô dict)
    wb_cache = {}
    for fname, b in uploaded_exports.items():
        try:
            wb_cache[fname] = openpyxl.load_workbook(io.BytesIO(b), data_only=True)
        except Exception:
            wb_cache[fname] = None

    # helper: ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö file_key
    def pick_file_for_key(file_key: str):
        if not uploaded_exports:
            return None
        key_norm = _strip_date_prefix(file_key)
        # exact by contains
        for fname in uploaded_exports.keys():
            if key_norm and key_norm in _strip_date_prefix(fname):
                return fname
        # fallback: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô
        if len(uploaded_exports) == 1:
            return list(uploaded_exports.keys())[0]
        return None

    results = []
    missing = []

    for row in mapping_rows:
        point_id = row["point_id"]
        file_key = row["file_key"]
        sheet = row.get("sheet") or "Sheet1"
        col = row.get("col") or ""
        t_hhmm = _normalize_scada_time(row.get("time"))

        fname = pick_file_for_key(file_key)
        if not fname or not wb_cache.get(fname):
            missing.append({**row, "reason": "NO_MATCH_FILE"})
            results.append({"point_id": point_id, "value": None, "file": file_key, "sheet": sheet, "time": t_hhmm, "col": col, "status": "NO_FILE"})
            continue

        wb = wb_cache[fname]
        if sheet not in wb.sheetnames:
            missing.append({**row, "reason": "NO_SHEET"})
            results.append({"point_id": point_id, "value": None, "file": file_key, "sheet": sheet, "time": t_hhmm, "col": col, "status": "NO_SHEET"})
            continue

        ws = wb[sheet]
        val, stt = _extract_value_from_ws(ws, t_hhmm, col)
        results.append({"point_id": point_id, "value": val, "file": file_key, "sheet": sheet, "time": t_hhmm, "col": col, "status": stt})

        if stt != "OK" or val is None:
            missing.append({**row, "reason": stt})

    return results, missing

def normalize_number_str(s: str, decimals: int = 0) -> str:
    if not s: return ""
    s = str(s).strip().replace(",", "").replace(" ", "")
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"\.{2,}", ".", s)
    if s.count(".") > 1:
        parts = [p for p in s.split(".") if p != ""]
        if len(parts) >= 2: s = parts[0] + "." + "".join(parts[1:])
        else: s = s.replace(".", "")
    if decimals == 0: s = s.replace(".", "")
    return s

def preprocess_text(text):
    patterns = [r'IP\s*51', r'50\s*Hz', r'Class\s*2', r'3x220/380\s*V', r'Type', r'Mitsubishi', r'Electric', r'Wire', r'kWh', r'MH\s*[-]?\s*96', r'30\s*\(100\)\s*A', r'\d+\s*rev/kWh', r'WATT-HOUR\s*METER', r'Indoor\s*Use', r'Made\s*in\s*Thailand']
    for p in patterns: text = re.sub(p, '', text, flags=re.IGNORECASE)
    text = re.sub(r'\b10,000\b', '', text)
    text = re.sub(r'\b1,000\b', '', text)
    text = re.sub(r'(?<=[\d\s])[\|Il!](?=[\d\s])', '1', text)
    text = re.sub(r'(?<=[\d\s])[Oo](?=[\d\s])', '0', text)
    return text

def is_digital_meter(config):
    blob = f"{config.get('type','')} {config.get('name','')} {config.get('keyword','')}".lower()
    return ("digital" in blob) or ("scada" in blob) or (int(config.get('decimals', 0) or 0) > 0)

def preprocess_image_cv(image_bytes, config, use_roi=True, variant="auto"):
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if img is None: return image_bytes

    H, W = img.shape[:2]
    if W > 1280:
        scale = 1280 / W
        img = cv2.resize(img, (1280, int(H * scale)), interpolation=cv2.INTER_AREA)
        H, W = img.shape[:2]

    if use_roi:
        x1, y1, x2, y2 = config.get('roi_x1', 0), config.get('roi_y1', 0), config.get('roi_x2', 0), config.get('roi_y2', 0)
        if x2 and y2:
            if 0 < x2 <= 1 and 0 < y2 <= 1:
                x1, y1, x2, y2 = int(float(x1) * W), int(float(y1) * H), int(float(x2) * W), int(float(y2) * H)
            else:
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            pad_x, pad_y = int(0.03 * W), int(0.03 * H)
            x1, y1 = max(0, x1 - pad_x), max(0, y1 - pad_y)
            x2, y2 = min(W, x2 + pad_x), min(H, y2 + pad_y)
            if x2 > x1 and y2 > y1:
                img = img[y1:y2, x1:x2]
                H, W = img.shape[:2]

    if config.get('ignore_red', False):
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        lower_red1 = np.array([0, 70, 50]);  upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([170, 70, 50]); upper_red2 = np.array([180, 255, 255])
        mask = cv2.inRange(hsv, lower_red1, upper_red1) + cv2.inRange(hsv, lower_red2, upper_red2)
        img[mask > 0] = [255, 255, 255]

    if variant == "raw":
        ok, encoded = cv2.imencode(".jpg", img)
        return encoded.tobytes() if ok else image_bytes

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if variant == "invert": gray = 255 - gray

    use_digital_logic = (variant == "soft") or (variant == "auto" and is_digital_meter(config))

    if use_digital_logic:
        if min(H, W) < 300:
            gray = cv2.resize(gray, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        g = clahe.apply(gray)
        blur = cv2.GaussianBlur(g, (0, 0), 1.0)
        sharp = cv2.addWeighted(g, 1.6, blur, -0.6, 0)
        ok, encoded = cv2.imencode(".png", sharp)
        return encoded.tobytes() if ok else image_bytes
    else:
        gray2 = cv2.bilateralFilter(gray, 7, 50, 50)
        th = cv2.adaptiveThreshold(gray2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 7)
        ok, encoded = cv2.imencode(".png", th)
        return encoded.tobytes() if ok else image_bytes

def _vision_read_text(processed_bytes):
    try:
        image = vision.Image(content=processed_bytes)
        ctx = vision.ImageContext(language_hints=["en"])
        resp = VISION_CLIENT.text_detection(image=image, image_context=ctx)
        if getattr(resp, "error", None) and resp.error.message: return "", resp.error.message
        if resp.text_annotations: return (resp.text_annotations[0].description or ""), ""
        
        resp2 = VISION_CLIENT.document_text_detection(image=image, image_context=ctx)
        txt = ""
        if resp2.full_text_annotation and resp2.full_text_annotation.text: txt = resp2.full_text_annotation.text
        return (txt or ""), ""
    except Exception as e:
        return "", str(e)

def ocr_process(image_bytes, config, debug=False):
    decimal_places = int(config.get('decimals', 0) or 0)
    keyword = str(config.get('keyword', '') or '').strip()
    expected_digits = int(config.get('expected_digits', 0) or 0)
    
    attempts = [
        ("ROI_auto",  True,  "auto"),
        ("ROI_raw",   True,  "raw"),
        ("ROI_soft",  True,  "soft"),
        ("ROI_inv",   True,  "invert"),
        ("FULL_auto", False, "auto"),
        ("FULL_raw",  False, "raw"),
    ]

    raw_full_text = ""
    for tag, use_roi, variant in attempts:
        processed = preprocess_image_cv(image_bytes, config, use_roi=use_roi, variant=variant)
        txt, err = _vision_read_text(processed)
        if txt and txt.strip():
            if any(c.isdigit() for c in txt):
                raw_full_text = (txt or "").replace("\n", " ")
                raw_full_text = re.sub(r"\.{2,}", ".", raw_full_text)
                break
    
    if not raw_full_text: return 0.0

    full_text = preprocess_text(raw_full_text)
    full_text = re.sub(r"\.{2,}", ".", full_text)

    def check_digits(val: float) -> bool:
        if expected_digits <= 0: return True
        try:
            ln = len(str(int(abs(float(val)))))
            return 1 <= ln <= expected_digits + 1
        except: return False

    def looks_like_spec_context(text: str, start: int, end: int) -> bool:
        ctx = text[max(0, start - 10):min(len(text), end + 10)].lower()
        if "kwh" in ctx or "kw h" in ctx: return False
        bad = ["hz", "volt", " v", "v ", "amp", " a", "a ", "class", "ip", "rev", "rpm", "phase", "3x", "indoor"]
        return any(b in ctx for b in bad)

    common_noise = {10, 30, 50, 60, 100, 220, 230, 240, 380, 400, 415, 1000, 10000}
    candidates = []

    if keyword:
        kw = re.escape(keyword)
        patterns = [kw + r"[^\d]*((?:\d|O|o|l|I|\|)+[\.,]?\d*)", r"((?:\d|O|o|l|I|\|)+[\.,]?\d*)[^\d]*" + kw]
        for pat in patterns:
            match = re.search(pat, raw_full_text, re.IGNORECASE)
            if match:
                val_str = match.group(1).replace("O", "0").replace("o", "0").replace("l", "1").replace("I", "1").replace("|", "1")
                val_str = normalize_number_str(val_str, decimal_places)
                try:
                    val = float(val_str)
                    if decimal_places > 0 and "." not in val_str: val = val / (10 ** decimal_places)
                    if check_digits(val): candidates.append({"val": float(val), "score": 600})
                except: pass

    clean_std = re.sub(r"\b202[0-9]\b|\b256[0-9]\b", "", full_text)
    clean_std = re.sub(r"\.{2,}", ".", clean_std)
    for m in re.finditer(r"-?(?:\d{1,3}(?:,\d{3})+|\d+)(?:\.\d+)?", clean_std):
        n_str = m.group(0)
        if looks_like_spec_context(raw_full_text, m.start(), m.end()): continue
        n_str2 = normalize_number_str(n_str, decimal_places)
        if not n_str2: continue
        try:
            val = float(n_str2) if "." in n_str2 else float(int(n_str2))
            if decimal_places > 0 and "." not in n_str2: val = val / (10 ** decimal_places)
            
            if int(abs(val)) in common_noise and not keyword: continue
            if not check_digits(val): continue

            score = 120
            int_part = str(int(abs(val)))
            score += min(len(int_part), 10) * 10
            if decimal_places > 0 and "." in n_str2: score += 25
            candidates.append({"val": float(val), "score": score})
        except: continue

    if candidates: return float(max(candidates, key=lambda x: x["score"])["val"])
    return 0.0

def calc_tolerance(decimals: int) -> float:
    if decimals <= 0: return 0.5
    return 0.5 * (10 ** (-decimals))
# =========================================================
# --- üî≥ QR + REF IMAGE HELPERS (Mobile) ---
# =========================================================
REF_IMAGE_FOLDER = "ref_images"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô Bucket

def get_ref_image_url(point_id: str) -> str:
    pid = str(point_id).strip().upper()
    return f"https://storage.googleapis.com/{BUCKET_NAME}/{REF_IMAGE_FOLDER}/{pid}.jpg"

def decode_qr(image_bytes: bytes):
    """‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ point_id ‡∏à‡∏≤‡∏Å QR (‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô None)"""
    try:
        arr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if img is None:
            return None
        detector = cv2.QRCodeDetector()
        data, _, _ = detector.detectAndDecode(img)
        data = (data or "").strip()
        return data.upper() if data else None
    except:
        return None

def infer_meter_type(config: dict) -> str:
    """‡πÄ‡∏î‡∏≤ meter_type ‡∏à‡∏≤‡∏Å config ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏≠‡∏Å‡∏ú‡∏¥‡∏î"""
    blob = f"{config.get('type','')} {config.get('name','')}".lower()
    if ("‡∏ô‡πâ‡∏≥" in blob) or ("water" in blob) or ("‡∏õ‡∏£‡∏∞‡∏õ‡∏≤" in blob):
        return "Water"
    return "Electric"
# =========================================================
# --- UI LOGIC ---
# =========================================================
mode = st.sidebar.radio(
    "üîß ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
    ["üìù ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏à‡∏î‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå", "üì• ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Excel (SCADA Export)", "üëÆ‚Äç‚ôÇÔ∏è Admin Approval"]
)
if mode == "üìù ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏à‡∏î‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå":
    st.title("Smart Meter System")
    st.markdown("### Water treatment Plant - Borthongindustrial")
    st.caption("Version 6.2 (QR-first for Mobile + Skip Confirm)")

    # --- session state ---
    if 'confirm_mode' not in st.session_state: st.session_state.confirm_mode = False
    if 'warning_msg' not in st.session_state: st.session_state.warning_msg = ""
    if 'last_manual_val' not in st.session_state: st.session_state.last_manual_val = 0.0

    if "emp_step" not in st.session_state: st.session_state.emp_step = "SCAN_QR"
    if "emp_point_id" not in st.session_state: st.session_state.emp_point_id = ""

    all_meters = load_points_master()
    if not all_meters:
        st.error("‚ùå ‡πÇ‡∏´‡∏•‡∏î PointsMaster ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
        st.stop()

    # --- ‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ö‡∏ô‡∏™‡∏∏‡∏î (‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô) ---
    c_insp, c_date = st.columns(2)
    with c_insp:
        inspector = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏ï‡∏£‡∏ß‡∏à", "Admin", key="emp_inspector")
    with c_date:
        selected_date = st.date_input(
            "üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡∏•‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ)",
            value=get_thai_time().date(),
            key="emp_date"
        )

    # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î mismatch confirm ‡πÉ‡∏´‡πâ‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°
    if st.session_state.get("confirm_mode", False):
        st.session_state.emp_point_id = st.session_state.get("last_point_id", st.session_state.emp_point_id)
        st.session_state.emp_step = "INPUT"

    # =========================================================
    # STEP 1: SCAN QR
    # =========================================================
    if st.session_state.emp_step == "SCAN_QR":
        st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏™‡πÅ‡∏Å‡∏ô QR ‡∏ó‡∏µ‡πà‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå")
        st.write("üìå ‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÉ‡∏Å‡∏•‡πâ ‡πÜ ‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 15‚Äì25 ‡∏ã‡∏°.)")

        qr_pic = st.camera_input("‡∏ñ‡πà‡∏≤‡∏¢ QR ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î", key="emp_qr_cam")
        if qr_pic is not None:
            pid = decode_qr(qr_pic.getvalue())
            if pid:
                st.session_state.emp_point_id = pid
                st.session_state.emp_step = "INPUT"
                st.rerun()
            else:
                st.warning("‡∏¢‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô QR ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô/‡πÉ‡∏Å‡∏•‡πâ‡∏Ç‡∏∂‡πâ‡∏ô")

        # --- ‡∏ó‡∏≤‡∏á‡∏´‡∏ô‡∏µ‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô (‡∏ã‡πà‡∏≠‡∏ô) ---
        with st.expander("‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ? ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏≠‡∏á"):
            manual_pid = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå point_id", key="emp_manual_pid")
            if st.button("‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏£‡∏´‡∏±‡∏™", use_container_width=True, key="emp_manual_ok"):
                if manual_pid.strip():
                    st.session_state.emp_point_id = manual_pid.strip().upper()
                    st.session_state.emp_step = "INPUT"
                    st.rerun()
                else:
                    st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏´‡∏±‡∏™‡∏Å‡πà‡∏≠‡∏ô")

        st.stop()

    # =========================================================
    # STEP 2: CONFIRM POINT (show name + ref image)
    # =========================================================
    if st.session_state.emp_step == "CONFIRM_POINT":
        pid = st.session_state.emp_point_id
        config = get_meter_config(pid)
        if not config:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö point_id: {pid} ‡πÉ‡∏ô PointsMaster")
            if st.button("‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏™‡πÅ‡∏Å‡∏ô‡πÉ‡∏´‡∏°‡πà", use_container_width=True):
                st.session_state.emp_step = "SCAN_QR"
                st.session_state.emp_point_id = ""
                st.rerun()
            st.stop()

        meter_type = infer_meter_type(config)

        st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à")
        st.write(f"**Point:** {pid}")
        if config.get("name"):
            st.write(f"**‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î:** {config.get('name')}")
        st.write(f"**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:** {'üíß Water' if meter_type=='Water' else '‚ö° Electric'}")
        # ‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å GCS ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå service account ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á public)
        ref_bytes, ref_path = load_ref_image_bytes_any(pid)
        if ref_bytes:
            st.image(ref_bytes, caption=f"‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Reference): {ref_path}", use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô bucket ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ")
            st.caption("‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ point_id ‡πÄ‡∏ä‡πà‡∏ô CH_S11D_106_....jpg ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô ref_images/CH_S11D_106.jpg")


        b1, b2 = st.columns(2)
        if b1.button("‚úÖ ‡πÉ‡∏ä‡πà‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ", type="primary", use_container_width=True):
            st.session_state.emp_step = "INPUT"
            st.rerun()
        if b2.button("‚ùå ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà / ‡∏™‡πÅ‡∏Å‡∏ô‡πÉ‡∏´‡∏°‡πà", use_container_width=True):
            st.session_state.emp_step = "SCAN_QR"
            st.session_state.emp_point_id = ""
            st.rerun()

        st.stop()

    # =========================================================
    # STEP 3: INPUT + PHOTO + SAVE
    # =========================================================
    # ‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ = emp_step == "INPUT"
    point_id = st.session_state.emp_point_id
    config = get_meter_config(point_id)
    if not config:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö config ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ")
        st.session_state.emp_step = "SCAN_QR"
        st.session_state.emp_point_id = ""
        st.stop()

    report_col = str(config.get('report_col', '-') or '-').strip()
    meter_type = infer_meter_type(config)

    st.write("---")
    c1, c2 = st.columns([2, 1])

    with c1:
        st.markdown(f"üìç ‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à: **{point_id}**")
        if config.get("name"):
            st.caption(config.get("name"))
        st.markdown(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: <span class='report-badge'>{report_col}</span>", unsafe_allow_html=True)
        if st.button("üîÅ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏∏‡∏î (‡∏™‡πÅ‡∏Å‡∏ô‡πÉ‡∏´‡∏°‡πà)", use_container_width=True, key="emp_change_point"):
            st.session_state.emp_step = "SCAN_QR"
            st.session_state.emp_point_id = ""
            st.session_state.confirm_mode = False
            st.rerun()

    with c2:
        decimals = int(config.get("decimals", 0) or 0)
        step = 1.0 if decimals == 0 else (0.1 if decimals == 1 else 0.01)
        fmt = "%.0f" if decimals == 0 else ("%.1f" if decimals == 1 else "%.2f")
        st.caption("‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏•‡πâ‡∏ß AI ‡∏à‡∏∞‡πÄ‡∏™‡∏ô‡∏≠‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")

    # --- (Optional) ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå ---
    with st.expander("üñºÔ∏è ‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ)"):
        ref_bytes, ref_path = load_ref_image_bytes_any(point_id)
        if ref_bytes:
            st.image(ref_bytes, caption="Reference: " + str(ref_path), use_container_width=True)
        else:
            st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Reference) ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô bucket")

    tab_cam, tab_up = st.tabs(["üì∑ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ", "üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î"])

    with tab_cam:
        img_cam = st.camera_input("‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå", key="emp_meter_cam")

    with tab_up:
        img_up = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", type=['jpg', 'png', 'jpeg'], key="emp_meter_upload")
        if img_up is not None:
            st.image(img_up, caption=f"‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: {getattr(img_up, 'name', 'upload')}", use_container_width=True)

    img_file = img_cam if img_cam is not None else img_up

    st.write("---")
    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û/‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‚Üí AI ‡πÄ‡∏™‡∏ô‡∏≠‡∏Ñ‡πà‡∏≤ ‚Üí ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")

    # --- ‡∏Å‡∏±‡∏ô OCR ‡∏£‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡πâ‡∏≤ rerun ---
    if "emp_ai_value" not in st.session_state:
        st.session_state.emp_ai_value = None
    if "emp_img_hash" not in st.session_state:
        st.session_state.emp_img_hash = ""

    if img_file is None:
        st.info("üì∑ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ (‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ) ‡πÅ‡∏•‡πâ‡∏ß AI ‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
        st.stop()

    img_bytes = img_file.getvalue()
    img_hash = hashlib.md5(img_bytes).hexdigest()

    # ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡∏õ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‚Üí ‡∏≠‡πà‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà
    if img_hash != st.session_state.emp_img_hash:
        st.session_state.emp_img_hash = img_hash
        with st.spinner("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤..."):
            st.session_state.emp_ai_value = float(ocr_process(img_bytes, config, debug=False))

    ai_val = float(st.session_state.emp_ai_value or 0.0)
    st.write(f"ü§ñ **AI ‡πÄ‡∏™‡∏ô‡∏≠‡∏Ñ‡πà‡∏≤:** {fmt % ai_val}")

    choice = st.radio(
        "‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡πÑ‡∏´‡∏ô?",
        ["‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ AI", "‚úçÔ∏è ‡πÅ‡∏Å‡πâ‡πÄ‡∏≠‡∏á"],
        horizontal=True,
        key="emp_choice"
    )

    if choice == "‚úçÔ∏è ‡πÅ‡∏Å‡πâ‡πÄ‡∏≠‡∏á":
        final_val = st.number_input(
            "‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á",
            value=float(ai_val),
            min_value=0.0,
            step=step,
            format=fmt,
            key="emp_override_val"
        )
        status = "CONFIRMED_MANUAL"
    else:
        final_val = float(ai_val)
        status = "CONFIRMED_AI"

    st.info(f"‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {fmt % float(final_val)}")

    col_save, col_retry = st.columns(2)

    if col_save.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤", type="primary", use_container_width=True):
        try:
            filename = f"{point_id}_{selected_date.strftime('%Y%m%d')}_{get_thai_time().strftime('%H%M%S')}.jpg"
            image_url = upload_image_to_storage(img_bytes, filename)

            ok = save_to_db(point_id, inspector, meter_type, float(final_val), float(ai_val), status, selected_date, image_url)
            if ok:
                ok_r, msg_r = export_to_real_report(point_id, float(final_val), inspector, report_col, selected_date, debug=True)
                if not ok_r:
                    st.warning('‚ö†Ô∏è ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ TEST waterreport ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ' + msg_r)
                st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

                # ‡πÑ‡∏õ‡∏à‡∏∏‡∏î‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                st.session_state.emp_ai_value = None
                st.session_state.emp_img_hash = ""
                st.session_state.emp_step = "SCAN_QR"
                st.session_state.emp_point_id = ""
                st.rerun()
            else:
                st.error("‚ùå Save Failed")
        except Exception as e:
            st.error(f"‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

    if col_retry.button("üîÅ ‡∏ñ‡πà‡∏≤‡∏¢/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà", use_container_width=True):
        st.session_state.emp_ai_value = None
        st.session_state.emp_img_hash = ""
        st.rerun()

elif mode == "üëÆ‚Äç‚ôÇÔ∏è Admin Approval":
    st.title("üëÆ‚Äç‚ôÇÔ∏è Admin Dashboard")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ô‡πâ‡∏≥/‡πÑ‡∏ü")
    if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä"): st.rerun()

    sh = gc.open(DB_SHEET_NAME)
    ws = sh.worksheet("DailyReadings")
    data = ws.get_all_records()
    pending = [d for d in data if str(d.get('Status', '')).strip().upper() == 'FLAGGED']

    if not pending: st.success("‚úÖ All Clear")
    else:
        for i, item in enumerate(pending):
            with st.container():
                st.markdown("---")
                c_info, c_val, c_act = st.columns([1.5, 1.5, 1])
                with c_info:
                    st.subheader(f"üö© {item.get('point_id')}")
                    st.caption(f"Inspector: {item.get('inspector')}")
                    img_url = item.get('image_url')
                    if img_url and img_url != '-' and str(img_url).startswith('http'):
                        st.image(img_url, width=220)
                    else:
                        st.warning("No Image")

                with c_val:
                    m_val = safe_float(item.get('Manual_Value'), 0.0)
                    a_val = safe_float(item.get('AI_Value'), 0.0)
                    options_map = {
                        f"üë§ ‡∏Ñ‡∏ô‡∏à‡∏î: {m_val}": m_val,
                        f"ü§ñ AI: {a_val}": a_val
                    }
                    selected_label = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á:", list(options_map.keys()), key=f"rad_{i}")
                    choice = options_map[selected_label]

                with c_act:
                    st.write("")
                    if st.button("‚úÖ ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥", key=f"btn_{i}", type="primary"):
                        try:
                            timestamp = str(item.get('timestamp', '')).strip()
                            point_id = str(item.get('point_id', '')).strip()
                            cells = ws.findall(timestamp)
                            updated = False
                            for cell in cells:
                                if str(ws.cell(cell.row, 3).value).strip() == point_id:
                                    ws.update_cell(cell.row, 7, "APPROVED")
                                    ws.update_cell(cell.row, 5, choice)
                                    config = get_meter_config(point_id)
                                    report_col = (config.get('report_col', '') if config else '')
                                    
                                    # ‚úÖ Parse timestamp ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Sheet ‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≠‡∏ï‡∏≠‡∏ô Approve
                                    try:
                                        dt_obj = datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
                                        approve_date = dt_obj.date()
                                    except:
                                        approve_date = get_thai_time().date() # fallback
                                        
                                    ok_r, msg_r = export_to_real_report(point_id, choice, str(item.get('inspector', '')), report_col, approve_date, debug=True)
                                    if not ok_r:
                                        st.warning('‚ö†Ô∏è ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ TEST waterreport ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ' + msg_r)
                                    updated = True; break
                            if updated: st.success("Approved!"); st.rerun()
                            else: st.warning("‡∏´‡∏≤ row ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠")
                        except Exception as e: st.error(f"Error approve: {e}")

elif mode == "üì• ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Excel (SCADA Export)":
    st.title("üì• ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Excel (SCADA Export)")
    st.caption("‡πÇ‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ SCADA: ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà SCADA export ‡∏°‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ + ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")

    st.info(
        "‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡∏õ.6)\n"
        "1) ‡∏Å‡∏î 'Browse files' ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏°‡∏≤ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå)\n"
        "2) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô' ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô WaterReport\n"
        "3) ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Excel' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤\n"
        "4) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Excel -> ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ô‡∏±‡πâ‡∏ô\n"
        "5) ‡∏Å‡∏î '‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport' ‡∏à‡∏ö ‚úÖ"
    )

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    report_date = st.date_input("üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏õ‡∏Å‡∏£‡∏≠‡∏Å‡πÉ‡∏ô WaterReport)", value=get_thai_time().date())
    report_date_str = report_date.strftime("%Y/%m/%d")

    # ‡πÇ‡∏´‡∏•‡∏î mapping
    st.subheader("1) ‡πÑ‡∏ü‡∏•‡πå Mapping (DB_Water_Scada.xlsx)")
    mapping_rows = []
    if os.path.exists("DB_Water_Scada.xlsx"):
        st.success("‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DB_Water_Scada.xlsx ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‚úÖ (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)")
        mapping_rows = load_scada_excel_mapping(local_path="DB_Water_Scada.xlsx")
    else:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DB_Water_Scada.xlsx ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô (‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å ‡πÜ)")
        uploaded_map = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î DB_Water_Scada.xlsx", type=["xlsx"])
        if uploaded_map is not None:
            mapping_rows = load_scada_excel_mapping(uploaded_bytes=uploaded_map.getvalue())

    if not mapping_rows:
        st.stop()

    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Excel export
    st.subheader("2) ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà SCADA export")
    exports = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå) ‡πÄ‡∏ä‡πà‡∏ô ...Daily_Report.xlsx, ...UF_System.xlsx, ...SMMT_Daily_Report.xlsx",
        type=["xlsx"],
        accept_multiple_files=True,
    )

    if not exports:
        st.stop()

    uploaded_exports = {f.name: f.getvalue() for f in exports}

    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤
    if st.button("üîé ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Excel"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Excel..."):
            results, missing = extract_scada_values_from_exports(mapping_rows, uploaded_exports)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        ok_count = sum(1 for r in results if r["status"] == "OK" and r["value"] is not None)
        st.success(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß {ok_count}/{len(results)} ‡∏à‡∏∏‡∏î")

        df_show = pd.DataFrame(results)
        st.dataframe(df_show, use_container_width=True)

        # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session
        st.session_state["excel_results"] = results
        st.session_state["excel_missing"] = missing

    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏™‡∏î‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏Å‡πâ/‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    if "excel_results" in st.session_state:
        results = st.session_state["excel_results"]
        missing = st.session_state.get("excel_missing", [])

        # ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢
        missing_point_ids = [m["point_id"] for m in missing]
        if missing_point_ids:
            st.warning("‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à/‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Excel: " + ", ".join(missing_point_ids))

        # ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢
        manual_inputs = {}
        with st.expander("‚úçÔ∏è ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Excel (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"):
            for pid in missing_point_ids:
                manual_inputs[pid] = st.text_input(f"{pid} (‡∏Å‡∏£‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)", value="")

        # ‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤ final
        final_values = {}
        for r in results:
            pid = r["point_id"]
            val = r["value"]
            if pid in manual_inputs and manual_inputs[pid].strip() != "":
                val = manual_inputs[pid].strip()
            final_values[pid] = val

        # ‡∏õ‡∏∏‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport
        st.subheader("3) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport")
        st.caption("‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ (‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á) ‡∏•‡∏á WaterReport ‡∏ï‡∏≤‡∏° report_col ‡πÉ‡∏ô PointsMaster")

        
        if st.button("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport (‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)"):
            inspector_name = "Admin"

            # 1) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (validate + ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤)
            report_items = []   # ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ WaterReport
            db_rows = []        # log ‡∏•‡∏á DailyReadings
            fail_list = []      # [(pid, reason), ...]

            for pid, val in final_values.items():
                pid_u = str(pid).strip().upper()
                if val is None or str(val).strip() == "":
                    continue

                cfg = get_meter_config(pid_u)
                if not cfg:
                    fail_list.append((pid_u, "NO_CONFIG_IN_POINTSMaster"))
                    continue

                report_col = str(cfg.get("report_col", "") or "").strip()
                if (not report_col) or (report_col in ("-", "‚Äî", "‚Äì")):
                    fail_list.append((pid_u, "NO_REPORT_COL_IN_POINTSMaster"))
                    continue

                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
                write_val = val
                try:
                    write_val = float(str(val).replace(",", "").strip())
                except Exception:
                    write_val = str(val).strip()

                report_items.append({
                    "point_id": pid_u,
                    "value": write_val,
                    "report_col": report_col
                })

                # ‡∏ó‡∏≥ log ‡∏•‡∏á DB (DailyReadings) ‚Äî timestamp = ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô + ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡πÑ‡∏ó‡∏¢)
                try:
                    meter_type = infer_meter_type(cfg)
                except Exception:
                    meter_type = "Electric"

                try:
                    current_time = get_thai_time().time()
                    record_ts = datetime.combine(report_date, current_time).strftime("%Y-%m-%d %H:%M:%S")
                except Exception:
                    record_ts = get_thai_time().strftime("%Y-%m-%d %H:%M:%S")

                db_rows.append([
                    record_ts,
                    meter_type,
                    pid_u,
                    inspector_name,
                    write_val,   # Manual_Value
                    write_val,   # AI_Value
                    "AUTO_EXCEL_SCADA",
                    "-"          # image_url
                ])

            if not report_items:
                st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ß‡πà‡∏≤‡∏á)")
                st.stop()

            # 2) log ‡∏•‡∏á DB ‡πÅ‡∏ö‡∏ö batch (‡∏•‡∏î requests)
            ok_db, db_msg = append_rows_dailyreadings_batch(db_rows)
            db_ok_count = len(db_rows) if ok_db else 0
            if not ok_db:
                # ‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏Ñ‡πà‡πÅ‡∏à‡πâ‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏•‡πá‡∏≠‡∏Å DB ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
                st.warning(f"‚ö†Ô∏è Log ‡∏•‡∏á DailyReadings ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {db_msg}")

            # 3) export ‡∏•‡∏á WaterReport ‡πÅ‡∏ö‡∏ö batch (‡∏•‡∏î Read requests)
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport..."):
                ok_pids, fail_report = export_many_to_real_report_batch(report_items, report_date, debug=True)

            report_ok = len(ok_pids)
            report_fail = fail_list + list(fail_report)

            st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á WaterReport ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {report_ok} ‡∏à‡∏∏‡∏î")
            st.info(f"üóÉÔ∏è Log ‡∏•‡∏á DailyReadings ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {db_ok_count} ‡∏à‡∏∏‡∏î")

            if report_fail:
                st.error(f"‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(report_fail)} ‡∏à‡∏∏‡∏î")
                st.write([[pid, reason] for pid, reason in report_fail])
        st.divider()
        st.info("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ñ‡πâ‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ '‡∏°‡∏µ‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ü 1 ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ export ‡∏°‡∏≤‡πÉ‡∏ô Excel' -> ‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ô‡πâ‡∏≥)")
